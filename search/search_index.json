{"config":{"lang":["en"],"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Selamat Datang Di Halaman Tugas Penambangan Data (Data mining) Profile : Nama : Defri Dwi Romadhon Harni Saputra Nim : 180411100152 Kelas : Penambangan Data 5D Jurusan : Teknik Informatika Angkatan : 2018 Dosen Pengampu : Mula'ab,S.Si.,M.kom Alamat : Ds.Duduklor Kec.Glagah Kab.Lamongan","title":"index"},{"location":"DECISION TREE/","text":"DECISION TREE \u00b6 decision tree merupakan metode klarifikasi yang sering digunakan atau metode paling polpuler ,keunggulannya adalah mudah di interprestasi oleh manusia .dicision tree merupakan suatu prediksi yang berupa pohon atau bisa disebut stuktur beriharki,konsep decision tree adalah mengubah data yang ada menjadi pohon keputusan dan aturan aturan keputusan. CARA MEMBUAT DECISION TREE \u00b6 \u200b Ada beberapa cara membuat decision tree disini saya akan membuat dengan cara mengurutkan poperty yang paling penting.sebulum itu kita harus tau rumus rumusnya berikut ini rumus dari entropy dan gain : $$ Entropy(S)={\\sum \\limits_{i=1}^{n} -pi\\quad log_2\\quad pi} $$ keterangan: S=Himpunan kasus n = jumlah partisi S pi= proposi Si terhadap S kemudian hitung nilai gain menggunakan rumus : $$ GAIN(S,A)= entropy(S)-{\\sum \\limits_{i=1}^{n} \\frac{|Si|}{|s|}*entropy(Si)} $$ keterangan: S=himpunan kasus n=jumlah partisi S |si|=proporsi terhadap S |s|=jumlah kasus dalam S untuk mempermudah penghitungan saya menggunakan fungsi pembantu, seperti fungsi banyak_elemen untuk mengecek ada berapa elemen dalam sebuah kolom atau fiture/class. # menentukan value atau jenis pada atribut def banyak_elemen (kolom, data): kelas=[] for i in range (len(data)): if data.values.tolist()[i][kolom] not in kelas: kelas.append(data.values.tolist()[i][kolom]) return kelas kelas=banyak_elemen(df.shape[1]-1, df) outlook=banyak_elemen(df.shape[1]-5,df) temp=banyak_elemen(df.shape[1]-4,df) humidity=banyak_elemen(df.shape[1]-3,df) windy=banyak_elemen(df.shape[1]-2,df) print(kelas,outlook,temp,humidity,windy)` ['no', 'yes'] ['sunny', 'overcast', 'rainy'] ['hot', 'mild', 'cool'] ['high', 'normal'] [False, True] Fungsi countvKelas untuk menghitung berapa perbandingan setiap elemen yang terdapat di class. # menentukan count value pada Kelas def countvKelas(kelas,kolomKelas,data): hasil=[] for x in range(len(kelas)): hasil.append(0) for i in range (len(data)): for j in range (len(kelas)): if data.values.tolist()[i][kolomKelas] == kelas[j]: hasil[j]+=1 return hasil pKelas=countvKelas(kelas,df.shape[1]-1,df) pKelas [5, 9] Fungsi entropy untuk Menghitung nilai entropy pada sebuah fiture/class. fungsi e_list untuk mempermudah penghitungan entropy setiap elemen di dalam sebuah fiture. # menentukan nilai entropy target def entropy(T): hasil=0 jumlah=0 for y in T: jumlah+=y for z in range (len(T)): if jumlah!=0: T[z]=T[z]/jumlah for i in T: if i != 0: hasil-=i*math.log(i,2) return hasil def e_list(atribut,n): temp=[] tx=t_list(atribut,n) for i in range (len(atribut)): ent=entropy(tx[i]) temp.append(ent) return temp tOutlook=t_list(outlook,5) tTemp=t_list(temp,4) tHum=t_list(humidity,3) tWin=t_list(windy,2) print(\"Sunny, Overcast, Rainy\",eOutlook) print(\"Hot, Mild, Cold\", eTemp) print(\"High, Normal\", eHum) print(\"False, True\", eWin) Sunny, Overcast, Rainy [0.9709505944546686, 0.0, 0.9709505944546686] Hot, Mild, Cold [1.0, 0.9182958340544896, 0.8112781244591328] High, Normal [0.9852281360342516, 0.5916727785823275] False, True [0.8112781244591328, 1.0] berikut contoh data yang akan di rubah menjadi decision tree \u200b 0 1 2 3 4 0 CASTEMER ID GENDER CAR TIPE SHIRT SIZE CLASS 1 1 M FAMILY SMALL C0 2 2 M SPORT MEDIUM C0 3 3 M SPORT MEDIUM C0 4 4 M SPORT LARGE C0 5 5 M SPORT EXTRA LARGE C0 6 6 M SPORT EXTRA LARGE C0 7 7 F SPORT SMALL C0 8 8 F SPORT SMALL C0 9 9 F SPORT MEDIUM C1 10 10 F LUXURY LARGE C1 11 11 M FAMILY LARGE C1 12 12 M FAMILY EXTRA LARGE C1 13 13 M FAMILY MEDIUM C1 14 14 M LUCURY EXTRA LARGE C1 15 15 F LUCURY SMALL C1 16 16 F LUCURY SMALL C1 17 17 F LUCURY MEDIUM C1 18 18 F LUCURY MEDIUM C1 19 19 F LUCURY MEDIUM C1 20 20 F LUCURY LARGE C1 pertama mencari *entropy(s)* dari kolom class di atas diket: co=10 = Pi=10/20 c1=10=Pi=10/20 $$ Entropy(S)={\\sum \\limits_{i=1}^{n} -pi\\quad log2\\quad pi} $$ $$ Entropy(S)= -10/20 * log2 10/20 -10/20 *log2 10/20 $$ $$ Entropy(S)= 1 $$ lalu kita menghitu gain setiap kolom di atas: $$ GAIN(GENDER)= entropy(S)-{\\sum \\limits_{i=1}^{n} \\frac{|Si|}{|s|}*entropy(Si)} $$ GAIN(GENDER)= 1-[10/20(6,4)+10/20(4,6)] = 1-10/20(-6/10 x log2 6/10 - 4/10 x log2 4/10) +10/20(-4/10 x log2 4/10 - 6/10 x log2 6/10 ) =1-(10/20 x 0,970951)+(10/20 x 0,970951) =1-(0,4485475+0,4485475) =1-0,970951 =0.029049 $$ GAIN(CAR\\quad TIPE)= entropy(S)-{\\sum \\limits_{i=1}^{n} \\frac{|Si|}{|s|}*entropy(Si)} $$ GAIN(CAR TIPE)= 1-[4/20(1,3)+8/20(8,0)+8/20(1,7)] = 1-4/20(-1/4 x log2 1/4 - 3/4 x log2 3/4) +8/20(-8/8 x log2 8/8 - 0/8 x log2 0/8 )+8/20(-1/8 x log2 1/8 - 7/8 x log2 7/8) =1-(0,162256+0+0,217426) =1-0,379681 =0,620319 GAIN(shirt hat)= 1-[5/20(3,2)+7/20(3,4)+4/20(2,2)+4/20(2,2)] = 1-5/20(-3/5 x log2 3/5 - 2/5 x log2 2/45 +7/20(-3/7 x log2 3/7 - 4/7 x log2 4/7 )+4/20(-2/4 x log2 2/4 - 2/2 x log2 2/2)+4/20(-2/4 log2 2/4-2/4 log2 2/4) =1-(0,242738+0,34483+0,2+0,2) =1-0,987567 =0,012433 MathJax.Hub.Config({ tex2jax: {inlineMath: [['$$','$$']]}});","title":"DECISION TREE"},{"location":"DECISION TREE/#decision-tree","text":"decision tree merupakan metode klarifikasi yang sering digunakan atau metode paling polpuler ,keunggulannya adalah mudah di interprestasi oleh manusia .dicision tree merupakan suatu prediksi yang berupa pohon atau bisa disebut stuktur beriharki,konsep decision tree adalah mengubah data yang ada menjadi pohon keputusan dan aturan aturan keputusan.","title":"DECISION TREE"},{"location":"DECISION TREE/#cara-membuat-decision-tree","text":"\u200b Ada beberapa cara membuat decision tree disini saya akan membuat dengan cara mengurutkan poperty yang paling penting.sebulum itu kita harus tau rumus rumusnya berikut ini rumus dari entropy dan gain : $$ Entropy(S)={\\sum \\limits_{i=1}^{n} -pi\\quad log_2\\quad pi} $$ keterangan: S=Himpunan kasus n = jumlah partisi S pi= proposi Si terhadap S kemudian hitung nilai gain menggunakan rumus : $$ GAIN(S,A)= entropy(S)-{\\sum \\limits_{i=1}^{n} \\frac{|Si|}{|s|}*entropy(Si)} $$ keterangan: S=himpunan kasus n=jumlah partisi S |si|=proporsi terhadap S |s|=jumlah kasus dalam S untuk mempermudah penghitungan saya menggunakan fungsi pembantu, seperti fungsi banyak_elemen untuk mengecek ada berapa elemen dalam sebuah kolom atau fiture/class. # menentukan value atau jenis pada atribut def banyak_elemen (kolom, data): kelas=[] for i in range (len(data)): if data.values.tolist()[i][kolom] not in kelas: kelas.append(data.values.tolist()[i][kolom]) return kelas kelas=banyak_elemen(df.shape[1]-1, df) outlook=banyak_elemen(df.shape[1]-5,df) temp=banyak_elemen(df.shape[1]-4,df) humidity=banyak_elemen(df.shape[1]-3,df) windy=banyak_elemen(df.shape[1]-2,df) print(kelas,outlook,temp,humidity,windy)` ['no', 'yes'] ['sunny', 'overcast', 'rainy'] ['hot', 'mild', 'cool'] ['high', 'normal'] [False, True] Fungsi countvKelas untuk menghitung berapa perbandingan setiap elemen yang terdapat di class. # menentukan count value pada Kelas def countvKelas(kelas,kolomKelas,data): hasil=[] for x in range(len(kelas)): hasil.append(0) for i in range (len(data)): for j in range (len(kelas)): if data.values.tolist()[i][kolomKelas] == kelas[j]: hasil[j]+=1 return hasil pKelas=countvKelas(kelas,df.shape[1]-1,df) pKelas [5, 9] Fungsi entropy untuk Menghitung nilai entropy pada sebuah fiture/class. fungsi e_list untuk mempermudah penghitungan entropy setiap elemen di dalam sebuah fiture. # menentukan nilai entropy target def entropy(T): hasil=0 jumlah=0 for y in T: jumlah+=y for z in range (len(T)): if jumlah!=0: T[z]=T[z]/jumlah for i in T: if i != 0: hasil-=i*math.log(i,2) return hasil def e_list(atribut,n): temp=[] tx=t_list(atribut,n) for i in range (len(atribut)): ent=entropy(tx[i]) temp.append(ent) return temp tOutlook=t_list(outlook,5) tTemp=t_list(temp,4) tHum=t_list(humidity,3) tWin=t_list(windy,2) print(\"Sunny, Overcast, Rainy\",eOutlook) print(\"Hot, Mild, Cold\", eTemp) print(\"High, Normal\", eHum) print(\"False, True\", eWin) Sunny, Overcast, Rainy [0.9709505944546686, 0.0, 0.9709505944546686] Hot, Mild, Cold [1.0, 0.9182958340544896, 0.8112781244591328] High, Normal [0.9852281360342516, 0.5916727785823275] False, True [0.8112781244591328, 1.0] berikut contoh data yang akan di rubah menjadi decision tree \u200b 0 1 2 3 4 0 CASTEMER ID GENDER CAR TIPE SHIRT SIZE CLASS 1 1 M FAMILY SMALL C0 2 2 M SPORT MEDIUM C0 3 3 M SPORT MEDIUM C0 4 4 M SPORT LARGE C0 5 5 M SPORT EXTRA LARGE C0 6 6 M SPORT EXTRA LARGE C0 7 7 F SPORT SMALL C0 8 8 F SPORT SMALL C0 9 9 F SPORT MEDIUM C1 10 10 F LUXURY LARGE C1 11 11 M FAMILY LARGE C1 12 12 M FAMILY EXTRA LARGE C1 13 13 M FAMILY MEDIUM C1 14 14 M LUCURY EXTRA LARGE C1 15 15 F LUCURY SMALL C1 16 16 F LUCURY SMALL C1 17 17 F LUCURY MEDIUM C1 18 18 F LUCURY MEDIUM C1 19 19 F LUCURY MEDIUM C1 20 20 F LUCURY LARGE C1 pertama mencari *entropy(s)* dari kolom class di atas diket: co=10 = Pi=10/20 c1=10=Pi=10/20 $$ Entropy(S)={\\sum \\limits_{i=1}^{n} -pi\\quad log2\\quad pi} $$ $$ Entropy(S)= -10/20 * log2 10/20 -10/20 *log2 10/20 $$ $$ Entropy(S)= 1 $$ lalu kita menghitu gain setiap kolom di atas: $$ GAIN(GENDER)= entropy(S)-{\\sum \\limits_{i=1}^{n} \\frac{|Si|}{|s|}*entropy(Si)} $$ GAIN(GENDER)= 1-[10/20(6,4)+10/20(4,6)] = 1-10/20(-6/10 x log2 6/10 - 4/10 x log2 4/10) +10/20(-4/10 x log2 4/10 - 6/10 x log2 6/10 ) =1-(10/20 x 0,970951)+(10/20 x 0,970951) =1-(0,4485475+0,4485475) =1-0,970951 =0.029049 $$ GAIN(CAR\\quad TIPE)= entropy(S)-{\\sum \\limits_{i=1}^{n} \\frac{|Si|}{|s|}*entropy(Si)} $$ GAIN(CAR TIPE)= 1-[4/20(1,3)+8/20(8,0)+8/20(1,7)] = 1-4/20(-1/4 x log2 1/4 - 3/4 x log2 3/4) +8/20(-8/8 x log2 8/8 - 0/8 x log2 0/8 )+8/20(-1/8 x log2 1/8 - 7/8 x log2 7/8) =1-(0,162256+0+0,217426) =1-0,379681 =0,620319 GAIN(shirt hat)= 1-[5/20(3,2)+7/20(3,4)+4/20(2,2)+4/20(2,2)] = 1-5/20(-3/5 x log2 3/5 - 2/5 x log2 2/45 +7/20(-3/7 x log2 3/7 - 4/7 x log2 4/7 )+4/20(-2/4 x log2 2/4 - 2/2 x log2 2/2)+4/20(-2/4 log2 2/4-2/4 log2 2/4) =1-(0,242738+0,34483+0,2+0,2) =1-0,987567 =0,012433 MathJax.Hub.Config({ tex2jax: {inlineMath: [['$$','$$']]}});","title":"CARA MEMBUAT DECISION TREE"},{"location":"Statistik Deskriptif/","text":"Statistika Deskriptif Pengertian : Statistika Deskriptif adalah metode representasi keseluruhan himpunandata spesifik dengan memberikan ringkasa pendek dan ukuran data. Statistika Deskriptif juga merupakan metode sederhana hanya mendeskriptiskan kondisi dari data yang dimiliki dalam tabeldiagram grafik dan lainnya yang ditampilkan dalam uraian singkat dan terbatas. Tipe Statistik Deskriptif : Mean \u00b6 Mean merupakan rata-rata keseluruhan angka.Mean didapatkan dari hasil penjumlahan dari keseluruhanangka yang dibagi dengan banyaknya angka itu sendiri.Untuk menghitung data,kita misalkan N data rumus berikut \u200b $$ \\bar x ={\\sum \\limits_{i=1}^{n} x_i \\over N} = {x_1 + x_2 + x_3 + ... + x_n \\over N} $$ Keterangan : x bar = x rata-rata =nilai rata-rata sampel x = data ke n n = banyak data Median \u00b6 Median Merupakan nilai tengah dari sebuah urutan data, median disimbolkan dengan me, Nilaidari Median akan samadengan nilai Quartil 2/Q2.dan dalam mencari median yang banyak n dari data ganjil dan genap memiliki cara perhitungan yang berbeda,dengan rumus sebagai berikut : $$ Me=Q_2 =\\left( \\begin{matrix} n+1 \\over 2 \\end{matrix} \\right), jika\\quad n\\quad ganjil $$ $$ Me=Q_2 =\\left( \\begin{matrix} {xn \\over 2 } {xn+1\\over 2} \\over 2 \\end{matrix} \\right), jika\\quad n\\quad genap $$ Keterangan : Me = Nilai tengah dari kelompok data N = banyak data Modus \u00b6 Modus merupakan nilai atau angka yang paling sering ditemukan dalam sebuah kelompok angka, atau data yang paling sering muncul, atau memiliki frekuensi tertinggi. Modus bisa dilambangkan dengan Mo. Dan dapat dihitung dengan rumus berikut : $$ M_o = Tb + p{b_1 \\over b_1 + b_2} $$ Keterangan : Mo = modusdari kelompok data Tb= Tepi bawah dari elemen modus B1 = selisih frekuensi antara elemen modus dengan elemet sebelumnya B2 = selisih frekuensi antara elemen modus dengan elemen sesudahnya p = panjang interval nilai B1 dan B2 -> adalah mutlak atau selalu positif Varians \u00b6 Varians yaitu ukuran penyebaran setiap nilai dalam suatu himpunan data dari rata-rata. proses mencari varian terdapat langkah yang harus dilakukan, mengambil ukuran jarak dari setiap nilai atau mengurangi rata-rata dari setiap nilai dalam data, kemudian hasil dari ukuran jarak tersebut dikuadratkan dan membagi jumlah kuadrat dengan jumlah nilai dalam himpunan data. Dan dapat dihitung dengan rumus berikut : $$ \\sigma^2 = {\\sum \\limits_{i=1}^{n} (x_i - \\bar x)^2 \\over n} $$ Keterangan : Xi = titik data X bar = rata-rata dari sebuah titik data n = banyak dari anggota data Standar Deviasi \u00b6 Standar deviasi merupakan simpanan baku atau ukuran dispersi kumpulandata relatif terhadap rata-rata atau lebih simplenya adalah akar kuadrat positif dari varian.dan dapat dihitung dengan rumus berikut: $$ \\sigma^ = \\sqrt {{\\sum \\limits_{i=1}^{n} (x_i - \\bar x)^2 \\over n}} $$ Keterangan : x1 = nilai x ke i x = rata-rata n = ukuran sampel Skewness \u00b6 Skewness adalah merupakan kemiringan atau ketidak simetrisan pada suatu distribusi statistic yaitu dimana kurva tampak condong ke kiri atau ke kanan. Skewness digunakan untuk menentukan seberapa jauh mana perbedaan suatu distribusi dengan distribusi normal. Dalam distribusi normal grafik muncul seperti kurva berbentuk lonceng. Skewness dapat dihitung menggunakan rumus sebagai berikut: $$ Skewness = {\\sum \\limits{i=1}^n (x_i - \\bar x)^i \\over (n- 1) \\sigma^3} $$ Keterangan : Xi = titik data x bar = rata rata dari distribusi n= jumlah titik dalam distribusi o = standar deviasi Quartile \u00b6 Quartile adalah merupakan nilai-nilai yang membagikan data yang telah diurutkan kedalam 4 bagian yang sama besar. Kuartil dinotasikan dengan mengunakan notasi Q. Kuartil terdiri dari 3, yaitu kuartil satu Q1, kuartil dua Q2, dan kuartil tiga Q3. Untuk menentukan kuartil kepada data tunggal, kita harus mempertimbangkan banyaknya data n terlebih dahulu. Penghitungan quartil tergantung dari kondisi banyaknya data tersebut, untuk mencari quatile kita dapat menggunakan rumus berikut ini: $$ Q_1 = (n + 1) {1\\over 4} $$ $$ Q_2 = (n + 1) {1\\over 2} $$ $$ Q_3 = (n + 1) {3\\over 4} $$ Keterangan : Q = nilai Quartil N = banyak data Penerapan Statistik Deskriptif Menggunakan Python \u00b6 Alat dan Bahan : \u00b6 Pada penerapan tersebut menggunakan 100 data random yang disimpan dalam bentuk .csv untuk mempermudah dalam penerapan tersebut, dan perlu disiapkan library python yang dapat didownload secara gratis. Library python dapat digunakan adalah sebagai berikut : 1.Pandas, dapat digunakan untuk data manajemen dan data analysis. 2.Scipy, adalah merupakan library berisi kumpulan algoritma atau fungsi matematika. Langkah-Langkah \u00b6 Pertama Pertama-tama masukan library yang sudah disiapkan from scipy import states import pandas as pd Kedua Selanjutnya memuat data Csv yang telah disiapkan df = pd . read_csv ( 'data.csv' ) df code gabungan dari hasil di atas. import pandas as pd from scipy import stats df = pd . read_excel ( 'Book2.xlsx' , sep = ';' ) data = { \"stats\" : [ 'Min' , 'Max' , 'Mean' , 'Standard Deviasi' , 'Variasi' , 'Skewnes' , 'Quantile 1' , 'Quantile 2' , 'Quantile 3' , 'Median' , 'Modus' ]} for i in df . columns : data [ i ] = [ df [ i ] . min (), df [ i ] . max (), df [ i ] . mean (), round ( df [ i ] . std (), 2 ), round ( df [ i ] . var (), 2 ), round ( df [ i ] . skew (), 2 ), df [ i ] . quantile ( 0.25 ), df [ i ] . quantile ( 0.5 ), df [ i ] . quantile ( 0.75 ), df [ i ] . median (), stats . mode ( df [ i ]) . mode [ 0 ]] tes = pd . DataFrame ( data ) tes . style . hide_index () Berikut hasil gabungan dari codeyang telah di buat untuk menampilkan program tabel dibawah ini : stats ALPRO LOGIKA PTI B.ING Min 0 0 0 0 Max 4 4 4 4 Mean 2.05611 2.02605 1.98196 1.9519 Standard Deviasi 1.42 1.39 1.46 1.42 Variasi 2 1.94 2.13 2.03 Skewnes -0.04 -0.03 0.03 0.08 Quantile 1 1 1 1 1 Quantile 2 2 2 2 2 Quantile 3 3 3 3 3 Median 2 2 2 2 Modus 4 3 0 1 Reverensi \u00b6 https://id.wikipedia.org/wiki/statistika_deskriptif https://rusmus.co.id/mean-median-modus-data-kelompok/ http://emerer.com/cara-menghitung-median-modus-mode-kuartil-dan-desil/ https://carasiiumi.com/cara-menghitung-standar-deviasi/ http://muhammadsurindra.blogspot.com/2015/11/tugas2-pengantar-statistika-kaliini.html MathJax.Hub.Config({ tex2jax: {inlineMath: [['$$','$$']]} });","title":"statistika deskriptif"},{"location":"Statistik Deskriptif/#mean","text":"Mean merupakan rata-rata keseluruhan angka.Mean didapatkan dari hasil penjumlahan dari keseluruhanangka yang dibagi dengan banyaknya angka itu sendiri.Untuk menghitung data,kita misalkan N data rumus berikut \u200b $$ \\bar x ={\\sum \\limits_{i=1}^{n} x_i \\over N} = {x_1 + x_2 + x_3 + ... + x_n \\over N} $$ Keterangan : x bar = x rata-rata =nilai rata-rata sampel x = data ke n n = banyak data","title":"Mean"},{"location":"Statistik Deskriptif/#median","text":"Median Merupakan nilai tengah dari sebuah urutan data, median disimbolkan dengan me, Nilaidari Median akan samadengan nilai Quartil 2/Q2.dan dalam mencari median yang banyak n dari data ganjil dan genap memiliki cara perhitungan yang berbeda,dengan rumus sebagai berikut : $$ Me=Q_2 =\\left( \\begin{matrix} n+1 \\over 2 \\end{matrix} \\right), jika\\quad n\\quad ganjil $$ $$ Me=Q_2 =\\left( \\begin{matrix} {xn \\over 2 } {xn+1\\over 2} \\over 2 \\end{matrix} \\right), jika\\quad n\\quad genap $$ Keterangan : Me = Nilai tengah dari kelompok data N = banyak data","title":"Median"},{"location":"Statistik Deskriptif/#modus","text":"Modus merupakan nilai atau angka yang paling sering ditemukan dalam sebuah kelompok angka, atau data yang paling sering muncul, atau memiliki frekuensi tertinggi. Modus bisa dilambangkan dengan Mo. Dan dapat dihitung dengan rumus berikut : $$ M_o = Tb + p{b_1 \\over b_1 + b_2} $$ Keterangan : Mo = modusdari kelompok data Tb= Tepi bawah dari elemen modus B1 = selisih frekuensi antara elemen modus dengan elemet sebelumnya B2 = selisih frekuensi antara elemen modus dengan elemen sesudahnya p = panjang interval nilai B1 dan B2 -> adalah mutlak atau selalu positif","title":"Modus"},{"location":"Statistik Deskriptif/#varians","text":"Varians yaitu ukuran penyebaran setiap nilai dalam suatu himpunan data dari rata-rata. proses mencari varian terdapat langkah yang harus dilakukan, mengambil ukuran jarak dari setiap nilai atau mengurangi rata-rata dari setiap nilai dalam data, kemudian hasil dari ukuran jarak tersebut dikuadratkan dan membagi jumlah kuadrat dengan jumlah nilai dalam himpunan data. Dan dapat dihitung dengan rumus berikut : $$ \\sigma^2 = {\\sum \\limits_{i=1}^{n} (x_i - \\bar x)^2 \\over n} $$ Keterangan : Xi = titik data X bar = rata-rata dari sebuah titik data n = banyak dari anggota data","title":"Varians"},{"location":"Statistik Deskriptif/#standar-deviasi","text":"Standar deviasi merupakan simpanan baku atau ukuran dispersi kumpulandata relatif terhadap rata-rata atau lebih simplenya adalah akar kuadrat positif dari varian.dan dapat dihitung dengan rumus berikut: $$ \\sigma^ = \\sqrt {{\\sum \\limits_{i=1}^{n} (x_i - \\bar x)^2 \\over n}} $$ Keterangan : x1 = nilai x ke i x = rata-rata n = ukuran sampel","title":"Standar Deviasi"},{"location":"Statistik Deskriptif/#skewness","text":"Skewness adalah merupakan kemiringan atau ketidak simetrisan pada suatu distribusi statistic yaitu dimana kurva tampak condong ke kiri atau ke kanan. Skewness digunakan untuk menentukan seberapa jauh mana perbedaan suatu distribusi dengan distribusi normal. Dalam distribusi normal grafik muncul seperti kurva berbentuk lonceng. Skewness dapat dihitung menggunakan rumus sebagai berikut: $$ Skewness = {\\sum \\limits{i=1}^n (x_i - \\bar x)^i \\over (n- 1) \\sigma^3} $$ Keterangan : Xi = titik data x bar = rata rata dari distribusi n= jumlah titik dalam distribusi o = standar deviasi","title":"Skewness"},{"location":"Statistik Deskriptif/#quartile","text":"Quartile adalah merupakan nilai-nilai yang membagikan data yang telah diurutkan kedalam 4 bagian yang sama besar. Kuartil dinotasikan dengan mengunakan notasi Q. Kuartil terdiri dari 3, yaitu kuartil satu Q1, kuartil dua Q2, dan kuartil tiga Q3. Untuk menentukan kuartil kepada data tunggal, kita harus mempertimbangkan banyaknya data n terlebih dahulu. Penghitungan quartil tergantung dari kondisi banyaknya data tersebut, untuk mencari quatile kita dapat menggunakan rumus berikut ini: $$ Q_1 = (n + 1) {1\\over 4} $$ $$ Q_2 = (n + 1) {1\\over 2} $$ $$ Q_3 = (n + 1) {3\\over 4} $$ Keterangan : Q = nilai Quartil N = banyak data","title":"Quartile"},{"location":"Statistik Deskriptif/#penerapan-statistik-deskriptif-menggunakan-python","text":"","title":"Penerapan Statistik Deskriptif Menggunakan Python"},{"location":"Statistik Deskriptif/#alat-dan-bahan","text":"Pada penerapan tersebut menggunakan 100 data random yang disimpan dalam bentuk .csv untuk mempermudah dalam penerapan tersebut, dan perlu disiapkan library python yang dapat didownload secara gratis. Library python dapat digunakan adalah sebagai berikut : 1.Pandas, dapat digunakan untuk data manajemen dan data analysis. 2.Scipy, adalah merupakan library berisi kumpulan algoritma atau fungsi matematika.","title":"Alat dan Bahan :"},{"location":"Statistik Deskriptif/#langkah-langkah","text":"Pertama Pertama-tama masukan library yang sudah disiapkan from scipy import states import pandas as pd Kedua Selanjutnya memuat data Csv yang telah disiapkan df = pd . read_csv ( 'data.csv' ) df code gabungan dari hasil di atas. import pandas as pd from scipy import stats df = pd . read_excel ( 'Book2.xlsx' , sep = ';' ) data = { \"stats\" : [ 'Min' , 'Max' , 'Mean' , 'Standard Deviasi' , 'Variasi' , 'Skewnes' , 'Quantile 1' , 'Quantile 2' , 'Quantile 3' , 'Median' , 'Modus' ]} for i in df . columns : data [ i ] = [ df [ i ] . min (), df [ i ] . max (), df [ i ] . mean (), round ( df [ i ] . std (), 2 ), round ( df [ i ] . var (), 2 ), round ( df [ i ] . skew (), 2 ), df [ i ] . quantile ( 0.25 ), df [ i ] . quantile ( 0.5 ), df [ i ] . quantile ( 0.75 ), df [ i ] . median (), stats . mode ( df [ i ]) . mode [ 0 ]] tes = pd . DataFrame ( data ) tes . style . hide_index () Berikut hasil gabungan dari codeyang telah di buat untuk menampilkan program tabel dibawah ini : stats ALPRO LOGIKA PTI B.ING Min 0 0 0 0 Max 4 4 4 4 Mean 2.05611 2.02605 1.98196 1.9519 Standard Deviasi 1.42 1.39 1.46 1.42 Variasi 2 1.94 2.13 2.03 Skewnes -0.04 -0.03 0.03 0.08 Quantile 1 1 1 1 1 Quantile 2 2 2 2 2 Quantile 3 3 3 3 3 Median 2 2 2 2 Modus 4 3 0 1","title":"Langkah-Langkah"},{"location":"Statistik Deskriptif/#reverensi","text":"https://id.wikipedia.org/wiki/statistika_deskriptif https://rusmus.co.id/mean-median-modus-data-kelompok/ http://emerer.com/cara-menghitung-median-modus-mode-kuartil-dan-desil/ https://carasiiumi.com/cara-menghitung-standar-deviasi/ http://muhammadsurindra.blogspot.com/2015/11/tugas2-pengantar-statistika-kaliini.html MathJax.Hub.Config({ tex2jax: {inlineMath: [['$$','$$']]} });","title":"Reverensi"},{"location":"Tugas 2 - Mengukur Jarak/","text":"Mengukur Jarak \u00b6 Pengukuran jarak memegang peran yang sangat penting dalam menentukan kemiripan atau keteraturan di antara data dan item. dengan hal ini di lakukan untuk mengetahui ,dengan sebagian cara seperti apa data dikatakan saling terkait, mirip ataupun tidak mirip, dan metode pengukuran jarak seperti apa yang diperlukan untuk membandingkannya. Pada proses clustering, tahapan menentukan atau mendeskripsikan nilai kuantitatif dari tingkat kemiripan atau ketidakmiripan data (proximity measure) memiliki peran yang sangat penting, sehingga perlu dilakukannya perbandingan beberapa tahap metode yang sering digunakan, yaitu jarak euclidean, manhattan, dan minkowski. Mengukur jarak menggunakan Eucliean Distance \u00b6 Euclidean distance yaitu merupakan salah satu metode perhitungan jarak yang digunakan untuk mengukur sebuah jarak dari 2(dua) buah titik dalam Euclidean space (meliputi bidang euclidean dua dimensi, tiga dimensi, atau bahkan lebih). Jarak yang paling dikenal dan yang paling digunakan untuk data numerik adalah jarak Euclidean. Ini adalah kasus khusus dari jarak Minkowski ketika m = 2. Jarak Euclidean berkinerja baik ketika digunakan untuk kumpulan data cluster kompak atau terisolasi . Mengukur jarak menggunakan Manhattan Distance \u00b6 Manhattan distance adalah kasus khusus dari jarak Minkowski distance pada m = 1. Seperti Minkowski Distance, Manhattan distance sensitif terhadap outlier. BIla ukuran ini digunakan dalam algoritma clustering , bentuk cluster adalah hyper-rectangular. Manhattan distance digunakan untuk menghitung perbedaan absolut (mutlak) antara koordinat sepasang objek. Rumus yang digunakan adalah sebagai berikut: $$ d _ { \\operatorname { man } } = \\sum _ { i = 1 } ^ { n } \\left| x _ { i } - y _ { i } \\right| $$ dimana m adalah merupakan bilangan riel positif xi dan yi merupakan dua vektor dalam satu ruang dimensi n implementasi ukuran jarak minkowski pada model clustering data atribut dilakukan normalisasi untuk mengukur dominasi dari atribut yang memiliki skala data besar,. Mengukur jarak menggunakan Minkowski Distance \u00b6 Minkowski distance yaitu merupakan sebuah metrik dalam ruang vektor di mana suatu norma didefinisikan (normed vector space) sekaligus dianggap menjadi sebagai generalisasi dari Euclidean distance dan Manhattan distance. Dalam pengukuran jarak objek menggunakan minkowski distance biasanya digunakan nilai p adalah 1 atau 2. Berikut dibawah ini rumus yang digunakan menghitung jarak dalam metode ini. $$ d _ { \\operatorname { min } } = ( \\ sum _ { i = 1 } ^ { n } | x _ { i } - y _ { i } | ^ { m } ) ^ { \\frac { 1 } { m } } , m \\geq 1 $$ MathJax.Hub.Config({ tex2jax: {inlineMath: [['$$','$$']]} }); Langkah mengukur jarak : \u00b6 #Tugas 2_Penambangan Data.csv import pandas as pd from scipy import stats df = pd . read_csv ( 'Tugas 2_Penambangan Data.csv' , nrows = 4 , sep = ';' ) df import scipy.spatial.distance as minko import itertools def minkowski ( x , y , data ): return sum ( x ) + sum ( y ) dfvalues = df . values . tolist () data = [ [ x [ 0 ], x [ 1 ], minko . minkowski ( dfvalues [ x [ 0 ]], dfvalues [ x [ 1 ]], 1 ) , minko . minkowski ( dfvalues [ x [ 0 ]], dfvalues [ x [ 1 ]], 2 )] for x in itertools . combinations ( range ( 4 ), 2 ) ] columns = [ 'x' , 'y' , 'Minkowski (m-1)' , 'Minkowski (m-2)' ] pd . DataFrame ( data , columns = columns ) numerical = [ 0 , 3 ] categorical = [ 1 , 2 , 6 , 7 ] binary = [ 4 , 5 , 8 ] ordinal = [ 1 , 2 ] def chordDist ( v1 , v2 , jnis ): jmlh = 0 normv1 = 0 normv2 = 0 for x in range ( len ( jnis )): normv1 = normv1 + ( int ( df . values . tolist ()[ v1 ][ jnis [ x ]]) ** 2 ) normv2 = normv2 + ( int ( df . values . tolist ()[ v1 ][ jnis [ x ]]) ** 2 ) jmlh = jmlh + ( int ( df . values . tolist ()[ v1 ][ jnis [ x ]]) * int ( df . values . tolist ()[ v2 ][ jnis [ x ]])) return (( 2 - ( 2 * jmlh / ( normv1 * normv2 ))) ** 0.5 ) from IPython.display import HTML , display import tabulate table = [ [ \"x\" ] + [ 'y' ] + [ \"Jarak\" ] + [ \"Numeric\" ] + [ \"Ordinal\" ] + [ \"Categorical\" ] + [ \"Binary\" ], [ 0 ] + [ 2 ] + [ 0 ] + [ \"{:.2f}\" . format ( chordDist ( 0 , 2 , numerical ))] + [ 0 ] + [ 0 ] + [ 0 ], [ 0 ] + [ 3 ] + [ 0 ] + [ \"{:.2f}\" . format ( chordDist ( 0 , 3 , numerical ))] + [ 0 ] + [ 0 ] + [ 0 ], [ 1 ] + [ 2 ] + [ 0 ] + [ \"{:.2f}\" . format ( chordDist ( 1 , 2 , numerical ))] + [ 0 ] + [ 0 ] + [ 0 ], [ 1 ] + [ 3 ] + [ 0 ] + [ \"{:.2f}\" . format ( chordDist ( 1 , 3 , numerical ))] + [ 0 ] + [ 0 ] + [ 0 ], [ 2 ] + [ 3 ] + [ 0 ] + [ \"{:.2f}\" . format ( chordDist ( 2 , 3 , numerical ))] + [ 0 ] + [ 0 ] + [ 0 ], ] display ( HTML ( tabulate . tabulate ( table , tablefmt = 'html' )))","title":"mengukur jarak"},{"location":"Tugas 2 - Mengukur Jarak/#mengukur-jarak","text":"Pengukuran jarak memegang peran yang sangat penting dalam menentukan kemiripan atau keteraturan di antara data dan item. dengan hal ini di lakukan untuk mengetahui ,dengan sebagian cara seperti apa data dikatakan saling terkait, mirip ataupun tidak mirip, dan metode pengukuran jarak seperti apa yang diperlukan untuk membandingkannya. Pada proses clustering, tahapan menentukan atau mendeskripsikan nilai kuantitatif dari tingkat kemiripan atau ketidakmiripan data (proximity measure) memiliki peran yang sangat penting, sehingga perlu dilakukannya perbandingan beberapa tahap metode yang sering digunakan, yaitu jarak euclidean, manhattan, dan minkowski.","title":"Mengukur Jarak"},{"location":"Tugas 2 - Mengukur Jarak/#mengukur-jarak-menggunakan-eucliean-distance","text":"Euclidean distance yaitu merupakan salah satu metode perhitungan jarak yang digunakan untuk mengukur sebuah jarak dari 2(dua) buah titik dalam Euclidean space (meliputi bidang euclidean dua dimensi, tiga dimensi, atau bahkan lebih). Jarak yang paling dikenal dan yang paling digunakan untuk data numerik adalah jarak Euclidean. Ini adalah kasus khusus dari jarak Minkowski ketika m = 2. Jarak Euclidean berkinerja baik ketika digunakan untuk kumpulan data cluster kompak atau terisolasi .","title":"Mengukur jarak menggunakan Eucliean Distance"},{"location":"Tugas 2 - Mengukur Jarak/#mengukur-jarak-menggunakan-manhattan-distance","text":"Manhattan distance adalah kasus khusus dari jarak Minkowski distance pada m = 1. Seperti Minkowski Distance, Manhattan distance sensitif terhadap outlier. BIla ukuran ini digunakan dalam algoritma clustering , bentuk cluster adalah hyper-rectangular. Manhattan distance digunakan untuk menghitung perbedaan absolut (mutlak) antara koordinat sepasang objek. Rumus yang digunakan adalah sebagai berikut: $$ d _ { \\operatorname { man } } = \\sum _ { i = 1 } ^ { n } \\left| x _ { i } - y _ { i } \\right| $$ dimana m adalah merupakan bilangan riel positif xi dan yi merupakan dua vektor dalam satu ruang dimensi n implementasi ukuran jarak minkowski pada model clustering data atribut dilakukan normalisasi untuk mengukur dominasi dari atribut yang memiliki skala data besar,.","title":"Mengukur jarak menggunakan Manhattan Distance"},{"location":"Tugas 2 - Mengukur Jarak/#mengukur-jarak-menggunakan-minkowski-distance","text":"Minkowski distance yaitu merupakan sebuah metrik dalam ruang vektor di mana suatu norma didefinisikan (normed vector space) sekaligus dianggap menjadi sebagai generalisasi dari Euclidean distance dan Manhattan distance. Dalam pengukuran jarak objek menggunakan minkowski distance biasanya digunakan nilai p adalah 1 atau 2. Berikut dibawah ini rumus yang digunakan menghitung jarak dalam metode ini. $$ d _ { \\operatorname { min } } = ( \\ sum _ { i = 1 } ^ { n } | x _ { i } - y _ { i } | ^ { m } ) ^ { \\frac { 1 } { m } } , m \\geq 1 $$ MathJax.Hub.Config({ tex2jax: {inlineMath: [['$$','$$']]} });","title":"Mengukur jarak menggunakan Minkowski Distance"},{"location":"Tugas 2 - Mengukur Jarak/#langkah-mengukur-jarak","text":"#Tugas 2_Penambangan Data.csv import pandas as pd from scipy import stats df = pd . read_csv ( 'Tugas 2_Penambangan Data.csv' , nrows = 4 , sep = ';' ) df import scipy.spatial.distance as minko import itertools def minkowski ( x , y , data ): return sum ( x ) + sum ( y ) dfvalues = df . values . tolist () data = [ [ x [ 0 ], x [ 1 ], minko . minkowski ( dfvalues [ x [ 0 ]], dfvalues [ x [ 1 ]], 1 ) , minko . minkowski ( dfvalues [ x [ 0 ]], dfvalues [ x [ 1 ]], 2 )] for x in itertools . combinations ( range ( 4 ), 2 ) ] columns = [ 'x' , 'y' , 'Minkowski (m-1)' , 'Minkowski (m-2)' ] pd . DataFrame ( data , columns = columns ) numerical = [ 0 , 3 ] categorical = [ 1 , 2 , 6 , 7 ] binary = [ 4 , 5 , 8 ] ordinal = [ 1 , 2 ] def chordDist ( v1 , v2 , jnis ): jmlh = 0 normv1 = 0 normv2 = 0 for x in range ( len ( jnis )): normv1 = normv1 + ( int ( df . values . tolist ()[ v1 ][ jnis [ x ]]) ** 2 ) normv2 = normv2 + ( int ( df . values . tolist ()[ v1 ][ jnis [ x ]]) ** 2 ) jmlh = jmlh + ( int ( df . values . tolist ()[ v1 ][ jnis [ x ]]) * int ( df . values . tolist ()[ v2 ][ jnis [ x ]])) return (( 2 - ( 2 * jmlh / ( normv1 * normv2 ))) ** 0.5 ) from IPython.display import HTML , display import tabulate table = [ [ \"x\" ] + [ 'y' ] + [ \"Jarak\" ] + [ \"Numeric\" ] + [ \"Ordinal\" ] + [ \"Categorical\" ] + [ \"Binary\" ], [ 0 ] + [ 2 ] + [ 0 ] + [ \"{:.2f}\" . format ( chordDist ( 0 , 2 , numerical ))] + [ 0 ] + [ 0 ] + [ 0 ], [ 0 ] + [ 3 ] + [ 0 ] + [ \"{:.2f}\" . format ( chordDist ( 0 , 3 , numerical ))] + [ 0 ] + [ 0 ] + [ 0 ], [ 1 ] + [ 2 ] + [ 0 ] + [ \"{:.2f}\" . format ( chordDist ( 1 , 2 , numerical ))] + [ 0 ] + [ 0 ] + [ 0 ], [ 1 ] + [ 3 ] + [ 0 ] + [ \"{:.2f}\" . format ( chordDist ( 1 , 3 , numerical ))] + [ 0 ] + [ 0 ] + [ 0 ], [ 2 ] + [ 3 ] + [ 0 ] + [ \"{:.2f}\" . format ( chordDist ( 2 , 3 , numerical ))] + [ 0 ] + [ 0 ] + [ 0 ], ] display ( HTML ( tabulate . tabulate ( table , tablefmt = 'html' )))","title":"Langkah mengukur jarak :"},{"location":"Tugas 3 - Missing Value with KNN/","text":"Missing Value with K Nearest Neighbor \u00b6 Missing Data merupakan suatu informasi yang tidak tersedia dalam suatu data. Missing data mempengaruhi hasil penelitian karena keberadaan missing data dapat mengurangi tingkat akurasi dari hasil penelitian. Missing data dapat diatasi dengan imputasi. Imputasi merupakan suatu metode yang mengatasi missing data dengan mengisi nilai yang hilang dengan suatu nilai berdasarkan informasi lain yang didapat dari data tersebut. Salah satu metode imputasi yaitu metode K Nearest Neighbor(KNN). Penelitian itu dilakukan untuk memprediksi seluruh nilai yang hilang dengan metode KNN. KNN bekerja dengan menghitung weight mean estimation berdasarkan jumlah K. K yaitu jumlah observasi terdekat yang akan digunakan. Dalam penelitian ini, K yang digunakan yaitu K = 1, K = 5, K = 10, K = 15, dan K=20. Mean Square Error (MSE) dan Mean Absolute Percentage Error (MAPE) digunakan untuk mengetahui ketepatan hasil imputasi. Berdasarkan seluruh nilai rata-rata MSE dan MAPE dari 10 replikasi, KNN terbaik pada missing data 10% dan 20% terjadi pada saat K = 10, sedangkan untuk missing data 30% terjadi saat K = 15. Imputasi dengan Metode KNN \u00b6 Salah satu metode yang sering digunakan untuk permasalahan imputasi missing data adalah yaitu KNN. Metode ini merupakan metode sederhana dan fleksibel karena dapat digunakan baik pada variabel dengan data kontinu maupun data diskrit (Mawarsari, 2012). Algoritma KNN : Tentukan Nilai K Tentukan jarak Euclidian antar instance pada dataset Dm dan dataset Dc Imputasi data hilang dengan seluruh rata-rata k tetangga terdekat di Dc Kelemahan dan Keuntungan KNN \u00b6 Keuntungan KNN metode ini dapat bisa digunakan untuk data yang bersifat kualitatif maupun kuantitatif, tanpa perlu sedikit membuat model prediksi, algoritma sederhana, KNN dibutuhkan untuk pertimbangan struktur korelasi data (Acuna, 2004). Sedangkan kelemahan KNN adalah adanya pemilihan fungsi jarak, dapat menggunakan Euclidean, Manhattan, Mahalanobis dan Pearson. # importing pandas as pd import pandas as pd # importing numpy as np import numpy as np # dictionary of lists dict = { 'First Score' :[ 100 , 90 , np . nan , 95 ], 'Second Score' : [ 30 , 45 , 56 , np . nan ], 'Third Score' :[ np . nan , 40 , 80 , 98 ]} # creating a dataframe from dictionary df = pd . DataFrame ( dict ) # filling missing value using fillna() df . fillna ( 0 )","title":"missing value"},{"location":"Tugas 3 - Missing Value with KNN/#missing-value-with-k-nearest-neighbor","text":"Missing Data merupakan suatu informasi yang tidak tersedia dalam suatu data. Missing data mempengaruhi hasil penelitian karena keberadaan missing data dapat mengurangi tingkat akurasi dari hasil penelitian. Missing data dapat diatasi dengan imputasi. Imputasi merupakan suatu metode yang mengatasi missing data dengan mengisi nilai yang hilang dengan suatu nilai berdasarkan informasi lain yang didapat dari data tersebut. Salah satu metode imputasi yaitu metode K Nearest Neighbor(KNN). Penelitian itu dilakukan untuk memprediksi seluruh nilai yang hilang dengan metode KNN. KNN bekerja dengan menghitung weight mean estimation berdasarkan jumlah K. K yaitu jumlah observasi terdekat yang akan digunakan. Dalam penelitian ini, K yang digunakan yaitu K = 1, K = 5, K = 10, K = 15, dan K=20. Mean Square Error (MSE) dan Mean Absolute Percentage Error (MAPE) digunakan untuk mengetahui ketepatan hasil imputasi. Berdasarkan seluruh nilai rata-rata MSE dan MAPE dari 10 replikasi, KNN terbaik pada missing data 10% dan 20% terjadi pada saat K = 10, sedangkan untuk missing data 30% terjadi saat K = 15.","title":"Missing Value with K Nearest Neighbor"},{"location":"Tugas 3 - Missing Value with KNN/#imputasi-dengan-metode-knn","text":"Salah satu metode yang sering digunakan untuk permasalahan imputasi missing data adalah yaitu KNN. Metode ini merupakan metode sederhana dan fleksibel karena dapat digunakan baik pada variabel dengan data kontinu maupun data diskrit (Mawarsari, 2012). Algoritma KNN : Tentukan Nilai K Tentukan jarak Euclidian antar instance pada dataset Dm dan dataset Dc Imputasi data hilang dengan seluruh rata-rata k tetangga terdekat di Dc","title":"Imputasi dengan Metode KNN"},{"location":"Tugas 3 - Missing Value with KNN/#kelemahan-dan-keuntungan-knn","text":"Keuntungan KNN metode ini dapat bisa digunakan untuk data yang bersifat kualitatif maupun kuantitatif, tanpa perlu sedikit membuat model prediksi, algoritma sederhana, KNN dibutuhkan untuk pertimbangan struktur korelasi data (Acuna, 2004). Sedangkan kelemahan KNN adalah adanya pemilihan fungsi jarak, dapat menggunakan Euclidean, Manhattan, Mahalanobis dan Pearson. # importing pandas as pd import pandas as pd # importing numpy as np import numpy as np # dictionary of lists dict = { 'First Score' :[ 100 , 90 , np . nan , 95 ], 'Second Score' : [ 30 , 45 , 56 , np . nan ], 'Third Score' :[ np . nan , 40 , 80 , 98 ]} # creating a dataframe from dictionary df = pd . DataFrame ( dict ) # filling missing value using fillna() df . fillna ( 0 )","title":"Kelemahan dan Keuntungan KNN"},{"location":"Tugas 5 - Clustering/","text":"CLUSTERING \u00b6 Clustering adalah metode penganalisaan data yang sering dimasukkan sebagai salah satu metode Data Mining yang tujuannya adalah untuk mengelompokkan data dengan karakteristik yang sama ke suatu wilayah yang sama dan data dengan karakteristik yang berbeda ke wilayah yang lain. \u200b Ada beberapa pendekatan yang digunakan dalam mengembangkan metode clustering, dua pendekatan utama adalah clustering dengan pendekatan partisi dan clustering dengan pendekatan hirarki. Clustering dengan pendekatan partisi atau sering disebut dengan partition-based clustering mengelompokkan data dengan memilah-milah data yang dianalisa ke dalam cluster-cluster yang ada. Clustering dengan pendekatan hirarki atau sering disebut dengan hierarchical clustering mengelompokkan data dengan membuat suatu hirarki berupa dendogram dimana data yang mirip akan ditempatkan pada hirarki yang berdekatan dan yang tidak pada hirarki yang berjauhan. Di samping kedua pendekatan tersebut, ada juga clustering dengan pendekatan automatic mapping (Self-Organising Map/SOM). Clustering dengan pendekatan partisi \u00b6 1. K-Means \u200b Salah satu metode yang banyak digunakan dalam melakukan clustering dengan partisi ini adalah metode k-means. Secara umum metode k-means ini melakukan proses pengelompokan dengan prosedur sebagai berikut: \u00b7 Tentukan jumlah cluster \u00b7 Alokasikan data secara random ke cluster yang ada \u00b7 Hitung rata-rata setiap cluster dari data yang tergabung di dalamnya \u00b7 Alokasikan kembali semua data ke cluster terdekat \u00b7 Ulang proses nomor 3, sampai tidak ada perubahan atau perubahan yang terjadi masih sudah di bawah treshold \u200b Prosedur dasar ini bisa berubah mengikuti pendekatan pengalokasian data yang diterapkan, apakah crisp atau fuzzy . Setelah meneliti clustering dari sudut yang lain, saya menemukan bahwa k-means clustering mempunyai beberapa kelemahan. Fungsi dari algoritma ini adalah mengelompokkan data kedalam beberapa cluster. karakteristik dari algoritma ini adalah : . Memiliki n buah data. . Input berupa jumlah data dan jumlah cluster (kelompok). . Pada setiap cluster/kelompok memiliki sebuah centroid yang mempresentasikan cluster tersebut. Algoritma K-Means \u00b6 \u200b Secara sederhana algoritma K-Means dimulai dari tahap berikut : . Pilih K buah titik centroid. . Menghitung jarak data dengan centroid. . Update nilai titik centroid. . Ulangi langkah 2 dan 3 sampai nilai dari titik centroid tidak lagi berubah. Rumus K-Means \u00b6 Metode K-Modes \u00b6 \u200b K-Modes merupakan pengembangan dari algoritma clustering K-means untuk menangani data kategorik di mana means diganti oleh modes. K-Modes menggunakan simple matching meassure dalam penentuan similarity dari suatu klaster. Metode K-Prototype \u00b6 \u200b Tujuan dari simulasi ini adalah mencoba menerapkan algoritma K-Prototype pada data campuran numerik dan kategorikal. Ada tahap preparation diperlakukan terhadap data point numerik normalisasi terlebih dahulu. Algoritma K-Prototype \u00b6 \u200b Sebelum masuk proses algoritma K-Prototypes tentukan jumlah k yang akan dibentuk batasannya minimal 2 dan maksimal \u221an atau n/2 dimana n adalah jumlah data point atau obyek . Tahap 1 : Tentukan K dengan inisial kluster z1, z2, ..., zk secara acak dari n buah titik {x1, x2, ..., xn} . Tahap 2 : Hitung jarak seluruh data point pada data set terhadap inisial kluster awal, alokasikan data point ke dalam cluster yang memiliki jarak prototype terdekat dengan object yang diukur. . Tahap 3 : Hitung titik pusat cluster yang baru setelah semua objek dialokasikan. Lalu realokasikan semua datapoint pada dataset terhadap prototype yang baru. . Tahap 4 : jika titik pusat cluster tidak berubah atau sudah konvergen maka proses algoritma berhenti tetapi jika titik pusat masih berubah-ubah secara signifikan maka proses kembali ke tahap 2 dan 3 hingga iterasi maksimum tercapai atau sudah tidak ada perpindahan objek. Rumus K-Prototype \u00b6 2. Mixture Modelling (Mixture Modeling) \u200b Mixture modelling merupakan metode pengelompokan data yang mirip dengan k-means dengan kelebihan penggunaan distribusi statistik dalam mendefinisikan setiap cluster yang ditemukan. Dibandingkan dengan k-means yang hanya menggunakan cluster center, penggunaan distribusi statistik ini mengijinkan kita untuk: \u00b7 Memodel data yang kita miliki dengan setting karakteristik yang berbeda-beda \u00b7 Jumlah cluster yang sesuai dengan keadaan data bisa ditemukan seiring dengan proses pemodelan karakteristik dari masing-masing cluster \u00b7 Hasil pemodelan clustering yang dilaksanakan bisa diuji tingkat keakuratannya \u200b Distribusi statistik yang digunakan bisa bermacam-macam mulai dari yang digunakan untuk data categorical sampai yang continuous, termasuk di antaranya distribusi binomial, multinomial, normal dan lain-lain. Beberapa distribusi yang bersifat tidak normal seperti distribusi Poisson, von-Mises, Gamma dan Student t, juga diterapkan untuk bisa mengakomodasi berbagai keadaan data yang ada di lapangan. Beberapa pendekatan multivariate juga banyak diterapkan untuk memperhitungkan tingkat keterkaitan antara variabel data yang satu dengan yang lainnya. Clustering dengan Pendekatan Hirarki \u00b6 \u200b Clustering dengan pendekatan hirarki mengelompokkan data yang mirip dalam hirarki yang sama dan yang tidak mirip di hirarki yang agak jauh. Ada dua metode yang sering diterapkan yaitu agglomerative hieararchical clustering dan divisive hierarchical clustering . Agglomerative melakukan proses clustering dari N cluster menjadi satu kesatuan cluster, dimana N adalah jumlah data, sedangkan divisive melakukan proses clustering yang sebaliknya yaitu dari satu cluster menjadi N cluster. \u200b Beberapa metode hierarchical clustering yang sering digunakan dibedakan menurut cara mereka untuk menghitung tingkat kemiripan. Ada yang menggunakan Single Linkage , Complete Linkage , Average Linkage , Average Group Linkage dan lain-lainnya. Seperti juga halnya dengan partition-based clustering , kita juga bisa memilih jenis jarak yang digunakan untuk menghitung tingkat kemiripan antar data. \u200b Salah satu cara untuk mempermudah pengembangan dendogram untuk hierarchical clustering ini adalah dengan membuat similarity matrix yang memuat tingkat kemiripan antar data yang dikelompokkan. Tingkat kemiripan bisa dihitung dengan berbagai macam cara seperti dengan Euclidean Distance Space. Berangkat dari similarity matrix ini, kita bisa memilih lingkage jenis mana yang akan digunakan untuk mengelompokkan data yang dianalisa. Clustering Dengan Pendekatan Automatic Mapping (Self-Organising Map/SOM) \u00b6 \u200b Self-Organising Map merupakan suatu tipe Artificial Neural Networks yang di-training secara unsupervised. SOM menghasilkan map yang terdiri dari output dalam dimensi yang rendah (2 atau 3 dimensi). Map ini berusaha mencari property dari input data. Komposisi input dan output dalam SOM mirip dengan komposisi dari proses feature scaling (multidimensional scaling). \u200b Walaupun proses learning yang dilakukan mirip dengan Artificial Neural Networks, tetapi proses untuk meng-assign input data ke map, lebih mirip dengan K-Means dan kNN Algorithm. Adapun prosedur yang ditempuh dalam melakukan clustering dengan SOM adalah sebagai berikut: \u00b7 Tentukan weight dari input data secara random \u00b7 Pilih salah satu input data \u00b7 Hitung tingkat kesamaan (dengan Eucledian) antara input data dan weight dari input data tersebut dan pilih input data yang memiliki kesamaan dengan weight yang ada (data ini disebut dengan Best Matching Unit (BMU)) \u00b7 Perbaharui weight dari input data dengan mendekatkan weight tersebut ke BMU dengan rumus: Wv(t+1) = Wv(t) + Theta(v, t) x Alpha(t) x (D(t) \u2013 Wv(t)) Dimana: o Wv(t) : Weight pada saat ke-t o Theta (v, t) : Fungsi neighbourhood yang tergantung pada Lattice distance antara BMU dengan neuron v. Umumnya bernilai 1 untuk neuron yang cukup dekat dengan BMU, dan 0 untuk yang sebaliknya. Penggunaan fungsi Gaussian juga memungkinkan. o Alpha (t) : Learning Coefficient yang berkurang secara monotonic o D(t) : Input data \u00b7 Tambah nilai t, sampai t < Lambda , dimana Lambda adalah jumlah iterasi MathJax.Hub.Config({ tex2jax: {inlineMath: [['$$','$$']]} });","title":"Clustering"},{"location":"Tugas 5 - Clustering/#clustering","text":"Clustering adalah metode penganalisaan data yang sering dimasukkan sebagai salah satu metode Data Mining yang tujuannya adalah untuk mengelompokkan data dengan karakteristik yang sama ke suatu wilayah yang sama dan data dengan karakteristik yang berbeda ke wilayah yang lain. \u200b Ada beberapa pendekatan yang digunakan dalam mengembangkan metode clustering, dua pendekatan utama adalah clustering dengan pendekatan partisi dan clustering dengan pendekatan hirarki. Clustering dengan pendekatan partisi atau sering disebut dengan partition-based clustering mengelompokkan data dengan memilah-milah data yang dianalisa ke dalam cluster-cluster yang ada. Clustering dengan pendekatan hirarki atau sering disebut dengan hierarchical clustering mengelompokkan data dengan membuat suatu hirarki berupa dendogram dimana data yang mirip akan ditempatkan pada hirarki yang berdekatan dan yang tidak pada hirarki yang berjauhan. Di samping kedua pendekatan tersebut, ada juga clustering dengan pendekatan automatic mapping (Self-Organising Map/SOM).","title":"CLUSTERING"},{"location":"Tugas 5 - Clustering/#clustering-dengan-pendekatan-partisi","text":"1. K-Means \u200b Salah satu metode yang banyak digunakan dalam melakukan clustering dengan partisi ini adalah metode k-means. Secara umum metode k-means ini melakukan proses pengelompokan dengan prosedur sebagai berikut: \u00b7 Tentukan jumlah cluster \u00b7 Alokasikan data secara random ke cluster yang ada \u00b7 Hitung rata-rata setiap cluster dari data yang tergabung di dalamnya \u00b7 Alokasikan kembali semua data ke cluster terdekat \u00b7 Ulang proses nomor 3, sampai tidak ada perubahan atau perubahan yang terjadi masih sudah di bawah treshold \u200b Prosedur dasar ini bisa berubah mengikuti pendekatan pengalokasian data yang diterapkan, apakah crisp atau fuzzy . Setelah meneliti clustering dari sudut yang lain, saya menemukan bahwa k-means clustering mempunyai beberapa kelemahan. Fungsi dari algoritma ini adalah mengelompokkan data kedalam beberapa cluster. karakteristik dari algoritma ini adalah : . Memiliki n buah data. . Input berupa jumlah data dan jumlah cluster (kelompok). . Pada setiap cluster/kelompok memiliki sebuah centroid yang mempresentasikan cluster tersebut.","title":"Clustering dengan pendekatan partisi"},{"location":"Tugas 5 - Clustering/#algoritma-k-means","text":"\u200b Secara sederhana algoritma K-Means dimulai dari tahap berikut : . Pilih K buah titik centroid. . Menghitung jarak data dengan centroid. . Update nilai titik centroid. . Ulangi langkah 2 dan 3 sampai nilai dari titik centroid tidak lagi berubah.","title":"Algoritma K-Means"},{"location":"Tugas 5 - Clustering/#rumus-k-means","text":"","title":"Rumus K-Means"},{"location":"Tugas 5 - Clustering/#metode-k-modes","text":"\u200b K-Modes merupakan pengembangan dari algoritma clustering K-means untuk menangani data kategorik di mana means diganti oleh modes. K-Modes menggunakan simple matching meassure dalam penentuan similarity dari suatu klaster.","title":"Metode K-Modes"},{"location":"Tugas 5 - Clustering/#metode-k-prototype","text":"\u200b Tujuan dari simulasi ini adalah mencoba menerapkan algoritma K-Prototype pada data campuran numerik dan kategorikal. Ada tahap preparation diperlakukan terhadap data point numerik normalisasi terlebih dahulu.","title":"Metode K-Prototype"},{"location":"Tugas 5 - Clustering/#algoritma-k-prototype","text":"\u200b Sebelum masuk proses algoritma K-Prototypes tentukan jumlah k yang akan dibentuk batasannya minimal 2 dan maksimal \u221an atau n/2 dimana n adalah jumlah data point atau obyek . Tahap 1 : Tentukan K dengan inisial kluster z1, z2, ..., zk secara acak dari n buah titik {x1, x2, ..., xn} . Tahap 2 : Hitung jarak seluruh data point pada data set terhadap inisial kluster awal, alokasikan data point ke dalam cluster yang memiliki jarak prototype terdekat dengan object yang diukur. . Tahap 3 : Hitung titik pusat cluster yang baru setelah semua objek dialokasikan. Lalu realokasikan semua datapoint pada dataset terhadap prototype yang baru. . Tahap 4 : jika titik pusat cluster tidak berubah atau sudah konvergen maka proses algoritma berhenti tetapi jika titik pusat masih berubah-ubah secara signifikan maka proses kembali ke tahap 2 dan 3 hingga iterasi maksimum tercapai atau sudah tidak ada perpindahan objek.","title":"Algoritma K-Prototype"},{"location":"Tugas 5 - Clustering/#rumus-k-prototype","text":"2. Mixture Modelling (Mixture Modeling) \u200b Mixture modelling merupakan metode pengelompokan data yang mirip dengan k-means dengan kelebihan penggunaan distribusi statistik dalam mendefinisikan setiap cluster yang ditemukan. Dibandingkan dengan k-means yang hanya menggunakan cluster center, penggunaan distribusi statistik ini mengijinkan kita untuk: \u00b7 Memodel data yang kita miliki dengan setting karakteristik yang berbeda-beda \u00b7 Jumlah cluster yang sesuai dengan keadaan data bisa ditemukan seiring dengan proses pemodelan karakteristik dari masing-masing cluster \u00b7 Hasil pemodelan clustering yang dilaksanakan bisa diuji tingkat keakuratannya \u200b Distribusi statistik yang digunakan bisa bermacam-macam mulai dari yang digunakan untuk data categorical sampai yang continuous, termasuk di antaranya distribusi binomial, multinomial, normal dan lain-lain. Beberapa distribusi yang bersifat tidak normal seperti distribusi Poisson, von-Mises, Gamma dan Student t, juga diterapkan untuk bisa mengakomodasi berbagai keadaan data yang ada di lapangan. Beberapa pendekatan multivariate juga banyak diterapkan untuk memperhitungkan tingkat keterkaitan antara variabel data yang satu dengan yang lainnya.","title":"Rumus K-Prototype"},{"location":"Tugas 5 - Clustering/#clustering-dengan-pendekatan-hirarki","text":"\u200b Clustering dengan pendekatan hirarki mengelompokkan data yang mirip dalam hirarki yang sama dan yang tidak mirip di hirarki yang agak jauh. Ada dua metode yang sering diterapkan yaitu agglomerative hieararchical clustering dan divisive hierarchical clustering . Agglomerative melakukan proses clustering dari N cluster menjadi satu kesatuan cluster, dimana N adalah jumlah data, sedangkan divisive melakukan proses clustering yang sebaliknya yaitu dari satu cluster menjadi N cluster. \u200b Beberapa metode hierarchical clustering yang sering digunakan dibedakan menurut cara mereka untuk menghitung tingkat kemiripan. Ada yang menggunakan Single Linkage , Complete Linkage , Average Linkage , Average Group Linkage dan lain-lainnya. Seperti juga halnya dengan partition-based clustering , kita juga bisa memilih jenis jarak yang digunakan untuk menghitung tingkat kemiripan antar data. \u200b Salah satu cara untuk mempermudah pengembangan dendogram untuk hierarchical clustering ini adalah dengan membuat similarity matrix yang memuat tingkat kemiripan antar data yang dikelompokkan. Tingkat kemiripan bisa dihitung dengan berbagai macam cara seperti dengan Euclidean Distance Space. Berangkat dari similarity matrix ini, kita bisa memilih lingkage jenis mana yang akan digunakan untuk mengelompokkan data yang dianalisa.","title":"Clustering dengan Pendekatan Hirarki"},{"location":"Tugas 5 - Clustering/#clustering-dengan-pendekatan-automatic-mapping-self-organising-mapsom","text":"\u200b Self-Organising Map merupakan suatu tipe Artificial Neural Networks yang di-training secara unsupervised. SOM menghasilkan map yang terdiri dari output dalam dimensi yang rendah (2 atau 3 dimensi). Map ini berusaha mencari property dari input data. Komposisi input dan output dalam SOM mirip dengan komposisi dari proses feature scaling (multidimensional scaling). \u200b Walaupun proses learning yang dilakukan mirip dengan Artificial Neural Networks, tetapi proses untuk meng-assign input data ke map, lebih mirip dengan K-Means dan kNN Algorithm. Adapun prosedur yang ditempuh dalam melakukan clustering dengan SOM adalah sebagai berikut: \u00b7 Tentukan weight dari input data secara random \u00b7 Pilih salah satu input data \u00b7 Hitung tingkat kesamaan (dengan Eucledian) antara input data dan weight dari input data tersebut dan pilih input data yang memiliki kesamaan dengan weight yang ada (data ini disebut dengan Best Matching Unit (BMU)) \u00b7 Perbaharui weight dari input data dengan mendekatkan weight tersebut ke BMU dengan rumus: Wv(t+1) = Wv(t) + Theta(v, t) x Alpha(t) x (D(t) \u2013 Wv(t)) Dimana: o Wv(t) : Weight pada saat ke-t o Theta (v, t) : Fungsi neighbourhood yang tergantung pada Lattice distance antara BMU dengan neuron v. Umumnya bernilai 1 untuk neuron yang cukup dekat dengan BMU, dan 0 untuk yang sebaliknya. Penggunaan fungsi Gaussian juga memungkinkan. o Alpha (t) : Learning Coefficient yang berkurang secara monotonic o D(t) : Input data \u00b7 Tambah nilai t, sampai t < Lambda , dimana Lambda adalah jumlah iterasi MathJax.Hub.Config({ tex2jax: {inlineMath: [['$$','$$']]} });","title":"Clustering Dengan Pendekatan Automatic Mapping (Self-Organising Map/SOM)"}]}